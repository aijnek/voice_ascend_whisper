lora:
  r: 8
  alpha: 16
  dropout: 0.05
  target_modules:
    - q_proj
    - v_proj
    - k_proj
  bias: none
  task_type: SEQ_2_SEQ_LM
